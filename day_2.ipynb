{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A logistic regression forward pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= torch.tensor([1.0])\n",
    "x1 = torch.tensor([1.1])\n",
    "w1 = torch.tensor([2.2], requires_grad=True)\n",
    "b = torch.tensor([0.0] , requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute in an output layer\n",
    "z = x1*w1+b\n",
    "a = torch.sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9183], grad_fn=<SigmoidBackward0>),\n",
       " tensor([2.4200], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.binary_cross_entropy(a,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0852, grad_fn=<BinaryCrossEntropyBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating w1 and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_L_w1 = grad(loss, w1, retain_graph=True)\n",
    "grad_L_b = grad(loss, b, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.0898]),)\n",
      "(tensor([-0.0817]),)\n"
     ]
    }
   ],
   "source": [
    "print(grad_L_w1)\n",
    "print(grad_L_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer perceptron with two hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self, num_inputs:int, num_output:int):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            #1st hidden layers\n",
    "            torch.nn.Linear(num_inputs,30), \n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # 2nd hidden layer\n",
    "            torch.nn.Linear(30,20),\n",
    "            torch.nn.ReLU(),\n",
    "\n",
    "            # Output layer \n",
    "            torch.nn.Linear(20, num_output)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiation of new NeuralNetwork model\n",
    "model = NeuralNetwork(num_inputs=50, num_output=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Printing our model summary \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parametres are:  2213\n"
     ]
    }
   ],
   "source": [
    "# Checking for total number of trainable parameters of our model \n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad==True)\n",
    "print(\"Total number of trainable parametres are: \", num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0281,  0.1284,  0.1009, -0.0112, -0.0781, -0.0553, -0.0560,  0.0784,\n",
      "        -0.0010, -0.0326, -0.1146,  0.0116,  0.0874,  0.0893,  0.0122,  0.1300,\n",
      "        -0.0350,  0.1099,  0.0790,  0.1249,  0.0729, -0.1273,  0.0692, -0.1022,\n",
      "        -0.0947, -0.0993, -0.0655, -0.1270,  0.1208, -0.0596,  0.0926,  0.1268,\n",
      "         0.0897,  0.1052,  0.0036, -0.1390,  0.0863, -0.1192,  0.0366, -0.0590,\n",
      "         0.0906,  0.0944, -0.0074, -0.0493,  0.1094, -0.0445, -0.1089, -0.0914,\n",
      "        -0.1354,  0.1046], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# we can access the corresponding weight parameter matrix(of a specifique layer) as follows\n",
    "print(model.layers[0].weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.0560, -0.0131,  0.1141,  0.0025,  0.0788,  0.1260,  0.0459,  0.0039,\n",
      "        -0.0099, -0.1152, -0.1105,  0.0472,  0.0131,  0.0366, -0.1277,  0.0792,\n",
      "        -0.0146,  0.0551, -0.0780,  0.0295,  0.0728, -0.1057,  0.0126, -0.0490,\n",
      "         0.1161, -0.0296, -0.0827, -0.0906, -0.0129,  0.0642],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4049, 0.7199, 0.1914, 0.1110, 0.2571, 0.9903, 0.5465, 0.6608, 0.7740,\n",
       "         0.4193, 0.8244, 0.0844, 0.2703, 0.9241, 0.3095, 0.1921, 0.0173, 0.0214,\n",
       "         0.5597, 0.1463, 0.0092, 0.9721, 0.6788, 0.8706, 0.6227, 0.4121, 0.1727,\n",
       "         0.0201, 0.0579, 0.0127, 0.4383, 0.5526, 0.9336, 0.4040, 0.0474, 0.1752,\n",
       "         0.9438, 0.8593, 0.6749, 0.1563, 0.5821, 0.2843, 0.7466, 0.6320, 0.8265,\n",
       "         0.4360, 0.9963, 0.6321, 0.8896, 0.5159]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random training data \n",
    "X = torch.rand((1,50))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1656, 0.0817, 0.0549]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model (Execute forward pass of a model)\n",
    "out = model(X)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1656, 0.0817, 0.0549]])\n"
     ]
    }
   ],
   "source": [
    "# This tells PyTorch that it doesn't need to keep track of the\n",
    "# gradients, which can result in significant savings in memory and\n",
    "# computation.\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(X)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3553, 0.3267, 0.3180]])\n"
     ]
    }
   ],
   "source": [
    "# Using softmax fonction as the activation function \n",
    "with torch.no_grad():\n",
    "    out =torch.softmax(model(X),dim=1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up efficient data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a small toy dataset\n",
    "\n",
    "# Train data \n",
    "X_train = torch.tensor([\n",
    "    [-1.2,3.1],\n",
    "    [-0.9,2.9],\n",
    "    [-0.5,2.6],\n",
    "    [2.3,-1.1],\n",
    "    [2.7,-1.5],\n",
    "])\n",
    "\n",
    "y_train = torch.tensor([0,0,0,1,1])\n",
    "\n",
    "# test data\n",
    "X_test = torch.tensor([\n",
    "    [-0.8,2.8],\n",
    "    [2.6,-1.6],\n",
    "    ])\n",
    "\n",
    "y_test = torch.tensor([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Custom ToyDataset class's purpose is to use it to instantiate a pytorch DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the custom Dataset class\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ToyDataset(Dataset):\n",
    "    def __init__(self, X , y):\n",
    "        self.feature = X\n",
    "        self.labels = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        one_x = self.feature[index]\n",
    "        one_y = self.labels[index]\n",
    "        return one_x, one_y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ToyDataset(X_train,y_train)\n",
    "test_ds = ToyDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating data loaders \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# train DataLoader\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size= 2,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Test DataLoader \n",
    "test_loader = DataLoader(\n",
    "    dataset=test_ds,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "\n",
      "\n",
      "Batch 2: tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "\n",
      "\n",
      "Batch 3: tensor([[ 2.7000, -1.5000]]) tensor([1])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate over the train_loader\n",
    "for idx, (x,y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\", x , y)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is desired to prevent deep neural networks getting caught in repetitive update\n",
    "cycles during training. To prevent this, it's recommended to set drop_last=True, which\n",
    "will drop the last batch in each epoch, as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train DataLoader\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_ds,\n",
    "    batch_size= 2,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: tensor([[-1.2000,  3.1000],\n",
      "        [-0.5000,  2.6000]]) tensor([0, 0])\n",
      "\n",
      "\n",
      "Batch 2: tensor([[ 2.3000, -1.1000],\n",
      "        [-0.9000,  2.9000]]) tensor([1, 0])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate once more over the train_loader\n",
    "for idx, (x,y) in enumerate(train_loader):\n",
    "    print(f\"Batch {idx+1}:\", x , y)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3 | Batch: 0/ 2 | train Loss: 0.75\n",
      "Epoch: 1/3 | Batch: 1/ 2 | train Loss: 0.65\n",
      "Epoch: 2/3 | Batch: 0/ 2 | train Loss: 0.44\n",
      "Epoch: 2/3 | Batch: 1/ 2 | train Loss: 0.13\n",
      "Epoch: 3/3 | Batch: 0/ 2 | train Loss: 0.03\n",
      "Epoch: 3/3 | Batch: 1/ 2 | train Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = NeuralNetwork(num_inputs=2, num_output=2)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.5)\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx,(features,labels) in enumerate(train_loader):\n",
    "        logits = model(features)\n",
    "\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs} | Batch: {batch_idx}/ {len(train_loader)} | train Loss: {loss:.2f}\")\n",
    "    model.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.8569, -4.1618],\n",
      "        [ 2.5382, -3.7548],\n",
      "        [ 2.0944, -3.1820],\n",
      "        [-1.4814,  1.4816],\n",
      "        [-1.7176,  1.7342]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        outputs = model(X_train)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using softmax to obtain the class membership probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0.9991,     0.0009],\n",
      "        [    0.9982,     0.0018],\n",
      "        [    0.9949,     0.0051],\n",
      "        [    0.0491,     0.9509],\n",
      "        [    0.0307,     0.9693]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "probas = torch.softmax(input=outputs, dim=1, dtype=float)\n",
    "print(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert these values into class labels predictions using PyTorch's\n",
    "argmax function, which returns the index position of the highest value in each\n",
    "row if we set dim=1 (setting dim=0 would return the highest value in each\n",
    "column, instead):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.argmax(probas, dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it is unnecessary to compute softmax probabilities to obtain the\n",
    "class labels. We could also apply the argmax function to the logits (outputs)\n",
    "directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.argmax(outputs, dim=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing predict values to real values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions == y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute the prediction accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dataloader):\n",
    "    model = model.eval()\n",
    "    correct = 0.0 \n",
    "    total_exemple = 0\n",
    "\n",
    "    for idx, (features,labels) in enumerate(dataloader):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(features)\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        compare = labels == predictions\n",
    "        correct += torch.sum(compare)\n",
    "        total_exemple += len(compare)\n",
    "\n",
    "    return (correct / total_exemple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy sur l'ensemble d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(model= model, dataloader = train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy de l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(model = model, dataloader = test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving an loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommanded way to how to save a model with pytorch \n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's state_dict is a Python dictionary object that maps each layer in\n",
    "the model to its trainable parameters (weights and biases). Note that\n",
    "\"model.pth\" is an arbitrary filename for the model file saved to disk. We can\n",
    "give it any name and file ending we like; however, .pth and .pt are the most\n",
    "common conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we saved the model, we can restore it from disk as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(2,2)\n",
    "\n",
    "model.load_state_dict(torch.load(f=\"model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The torch.load(\"model.pth\") function reads the file \"model.pth\" and\n",
    "reconstructs the Python dictionary object containing the model's parameters\n",
    "while model.load_state_dict() applies these parameters to the model,\n",
    "effectively restoring its learned state from when we saved it.\n",
    "\n",
    "\n",
    "Note that the line model = NeuralNetwork(2, 2) above is not strictly\n",
    "necessary if you execute this code in the same session where you saved a\n",
    "model. However, I included it here to illustrate that we need an instance of\n",
    "the model in memory to apply the saved parameters. Here, the\n",
    "NeuralNetwork(2, 2) architecture needs to match the original saved model\n",
    "exactly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".torch_2_0_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
